INFO: [numexpr.utils] Note: NumExpr detected 20 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO: [numexpr.utils] NumExpr defaulting to 8 threads.
INFO: [root] num_labels: 2
INFO: [root] Detected label names: ['Auszubildende', 'Sonstige Arbeitnehmer']
Some weights of the model checkpoint at distilbert-base-german-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/1 [00:00<?, ?ba/s]  0%|          | 0/1 [00:00<?, ?ba/s]
WARNING: [evaluate.loading] Using the latest cached version of the module from C:\Users\Admin\.cache\huggingface\modules\evaluate_modules\metrics\evaluate-metric--precision\4e7f439a346715f68500ce6f2be82bf3272abd3f20bdafd203a2c4f85b61dd5f (last modified on Mon Dec 19 10:49:43 2022) since it couldn't be found locally at evaluate-metric--precision, or remotely on the Hugging Face Hub.
WARNING: [evaluate.loading] Using the latest cached version of the module from C:\Users\Admin\.cache\huggingface\modules\evaluate_modules\metrics\evaluate-metric--recall\e40e6e98d18ff3f210f4d0b26fa721bfaa80704b1fdf890fa551cfabf94fc185 (last modified on Mon Dec 19 10:49:44 2022) since it couldn't be found locally at evaluate-metric--recall, or remotely on the Hugging Face Hub.
WARNING: [evaluate.loading] Using the latest cached version of the module from C:\Users\Admin\.cache\huggingface\modules\evaluate_modules\metrics\evaluate-metric--accuracy\f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Mon Dec 19 10:49:46 2022) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.
WARNING: [evaluate.loading] Using the latest cached version of the module from C:\Users\Admin\.cache\huggingface\modules\evaluate_modules\metrics\evaluate-metric--f1\0ca73f6cf92ef5a268320c697f7b940d1030f8471714bffdb6856c641b818974 (last modified on Mon Dec 19 10:49:47 2022) since it couldn't be found locally at evaluate-metric--f1, or remotely on the Hugging Face Hub.
The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, label_class, id, text. If __index_level_0__, label_class, id, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.
***** Running training *****
  Num examples = 350
  Num Epochs = 5
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 220
  Number of trainable parameters = 67007234
  0%|          | 0/220 [00:00<?, ?it/s]You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/220 [00:00<02:20,  1.56it/s]  1%|          | 2/220 [00:00<01:13,  2.96it/s]  1%|1         | 3/220 [00:00<00:50,  4.29it/s]  2%|1         | 4/220 [00:00<00:41,  5.25it/s]  2%|2         | 5/220 [00:01<00:35,  5.99it/s]  3%|2         | 6/220 [00:01<00:31,  6.79it/s]  3%|3         | 7/220 [00:01<00:28,  7.41it/s]  4%|3         | 8/220 [00:01<00:27,  7.59it/s]  4%|4         | 9/220 [00:01<00:27,  7.71it/s]  5%|4         | 10/220 [00:01<00:26,  7.80it/s]  5%|5         | 11/220 [00:01<00:26,  7.85it/s]  5%|5         | 12/220 [00:01<00:26,  7.89it/s]  6%|5         | 13/220 [00:02<00:26,  7.93it/s]  6%|6         | 14/220 [00:02<00:26,  7.74it/s]  7%|7         | 16/220 [00:02<00:24,  8.26it/s]  8%|7         | 17/220 [00:02<00:24,  8.46it/s]  8%|8         | 18/220 [00:02<00:24,  8.33it/s]  9%|8         | 19/220 [00:02<00:24,  8.24it/s]  9%|9         | 20/220 [00:02<00:24,  8.17it/s] 10%|9         | 21/220 [00:03<00:24,  8.12it/s] 10%|#         | 22/220 [00:03<00:23,  8.39it/s] 10%|#         | 23/220 [00:03<00:23,  8.27it/s] 11%|#         | 24/220 [00:03<00:23,  8.51it/s] 11%|#1        | 25/220 [00:03<00:23,  8.35it/s] 12%|#1        | 26/220 [00:03<00:22,  8.57it/s] 12%|#2        | 27/220 [00:03<00:22,  8.40it/s] 13%|#2        | 28/220 [00:03<00:23,  8.27it/s] 13%|#3        | 29/220 [00:04<00:22,  8.51it/s] 14%|#3        | 30/220 [00:04<00:21,  8.69it/s] 14%|#4        | 31/220 [00:04<00:22,  8.47it/s] 15%|#4        | 32/220 [00:04<00:22,  8.33it/s] 15%|#5        | 33/220 [00:04<00:22,  8.22it/s] 15%|#5        | 34/220 [00:04<00:21,  8.48it/s] 16%|#5        | 35/220 [00:04<00:21,  8.67it/s] 16%|#6        | 36/220 [00:04<00:21,  8.45it/s] 17%|#6        | 37/220 [00:04<00:21,  8.65it/s] 17%|#7        | 38/220 [00:05<00:21,  8.44it/s] 18%|#7        | 39/220 [00:05<00:20,  8.64it/s] 18%|#8        | 40/220 [00:05<00:21,  8.44it/s] 19%|#8        | 41/220 [00:05<00:21,  8.30it/s] 19%|#9        | 42/220 [00:05<00:21,  8.21it/s] 20%|#9        | 43/220 [00:05<00:21,  8.14it/s]                                                {'loss': 0.5965, 'learning_rate': 8e-07, 'epoch': 1.0}
 20%|##        | 44/220 [00:05<00:21,  8.14it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, label_class, id, text. If __index_level_0__, label_class, id, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 150
  Batch size = 8

  0%|          | 0/19 [00:00<?, ?it/s][A
 21%|##1       | 4/19 [00:00<00:00, 36.59it/s][A
 42%|####2     | 8/19 [00:00<00:00, 29.21it/s][A
 63%|######3   | 12/19 [00:00<00:00, 28.86it/s][A
 79%|#######8  | 15/19 [00:00<00:00, 28.38it/s][A
 95%|#########4| 18/19 [00:00<00:00, 28.07it/s][A                                                
                                               [A{'eval_loss': 0.5565794110298157, 'eval_precision': 0.8523489932885906, 'eval_recall': 0.9921875, 'eval_accuracy': 0.8466666666666667, 'eval_f1': 0.9169675090252708, 'eval_runtime': 0.7033, 'eval_samples_per_second': 213.288, 'eval_steps_per_second': 27.016, 'epoch': 1.0}
 20%|##        | 44/220 [00:06<00:21,  8.14it/s]
100%|##########| 19/19 [00:00<00:00, 28.07it/s][A
                                               [A 20%|##        | 45/220 [00:06<00:48,  3.58it/s] 21%|##        | 46/220 [00:06<00:41,  4.15it/s] 21%|##1       | 47/220 [00:06<00:35,  4.84it/s] 22%|##1       | 48/220 [00:06<00:31,  5.43it/s] 22%|##2       | 49/220 [00:07<00:27,  6.12it/s] 23%|##2       | 50/220 [00:07<00:25,  6.56it/s] 23%|##3       | 51/220 [00:07<00:24,  6.92it/s] 24%|##3       | 52/220 [00:07<00:22,  7.45it/s] 24%|##4       | 53/220 [00:07<00:21,  7.61it/s] 25%|##4       | 54/220 [00:07<00:21,  7.72it/s] 25%|##5       | 55/220 [00:07<00:21,  7.80it/s] 25%|##5       | 56/220 [00:07<00:20,  8.16it/s] 26%|##5       | 57/220 [00:08<00:19,  8.43it/s] 26%|##6       | 58/220 [00:08<00:19,  8.30it/s] 27%|##6       | 59/220 [00:08<00:19,  8.21it/s] 27%|##7       | 60/220 [00:08<00:19,  8.14it/s] 28%|##7       | 61/220 [00:08<00:18,  8.42it/s] 28%|##8       | 62/220 [00:08<00:19,  8.29it/s] 29%|##8       | 63/220 [00:08<00:19,  8.20it/s] 29%|##9       | 64/220 [00:08<00:19,  8.14it/s] 30%|##9       | 65/220 [00:08<00:18,  8.41it/s] 30%|###       | 66/220 [00:09<00:17,  8.61it/s] 30%|###       | 67/220 [00:09<00:18,  8.42it/s] 31%|###       | 68/220 [00:09<00:18,  8.29it/s] 31%|###1      | 69/220 [00:09<00:17,  8.53it/s] 32%|###1      | 70/220 [00:09<00:17,  8.70it/s] 32%|###2      | 71/220 [00:09<00:18,  8.16it/s] 33%|###2      | 72/220 [00:09<00:17,  8.43it/s] 33%|###3      | 73/220 [00:09<00:17,  8.29it/s] 34%|###3      | 74/220 [00:10<00:17,  8.53it/s] 34%|###4      | 75/220 [00:10<00:16,  8.71it/s] 35%|###4      | 76/220 [00:10<00:16,  8.48it/s] 35%|###5      | 77/220 [00:10<00:17,  8.33it/s] 35%|###5      | 78/220 [00:10<00:17,  8.23it/s] 36%|###5      | 79/220 [00:10<00:16,  8.48it/s] 36%|###6      | 80/220 [00:10<00:16,  8.33it/s] 37%|###6      | 81/220 [00:10<00:16,  8.23it/s] 37%|###7      | 82/220 [00:11<00:16,  8.16it/s] 38%|###7      | 83/220 [00:11<00:16,  8.43it/s] 38%|###8      | 84/220 [00:11<00:15,  8.63it/s] 39%|###8      | 85/220 [00:11<00:16,  8.43it/s] 39%|###9      | 86/220 [00:11<00:15,  8.63it/s] 40%|###9      | 87/220 [00:11<00:15,  8.43it/s]                                                {'loss': 0.5035, 'learning_rate': 6e-07, 'epoch': 2.0}
 40%|####      | 88/220 [00:11<00:15,  8.43it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, label_class, id, text. If __index_level_0__, label_class, id, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 150
  Batch size = 8

  0%|          | 0/19 [00:00<?, ?it/s][A
 21%|##1       | 4/19 [00:00<00:00, 36.60it/s][A
 42%|####2     | 8/19 [00:00<00:00, 31.32it/s][A
 63%|######3   | 12/19 [00:00<00:00, 28.42it/s][A
 79%|#######8  | 15/19 [00:00<00:00, 28.09it/s][A
 95%|#########4| 18/19 [00:00<00:00, 27.84it/s][A
                                               [A                                                {'eval_loss': 0.49989786744117737, 'eval_precision': 0.8533333333333334, 'eval_recall': 1.0, 'eval_accuracy': 0.8533333333333334, 'eval_f1': 0.9208633093525179, 'eval_runtime': 0.7033, 'eval_samples_per_second': 213.266, 'eval_steps_per_second': 27.014, 'epoch': 2.0}

100%|##########| 19/19 [00:00<00:00, 27.84it/s][A 40%|####      | 88/220 [00:12<00:15,  8.43it/s]
                                               [A 40%|####      | 89/220 [00:12<00:36,  3.61it/s] 41%|####      | 90/220 [00:12<00:30,  4.25it/s] 41%|####1     | 91/220 [00:12<00:26,  4.84it/s] 42%|####1     | 92/220 [00:12<00:23,  5.43it/s] 42%|####2     | 93/220 [00:12<00:20,  6.12it/s] 43%|####2     | 94/220 [00:13<00:19,  6.56it/s] 43%|####3     | 95/220 [00:13<00:18,  6.92it/s] 44%|####3     | 96/220 [00:13<00:17,  7.21it/s] 44%|####4     | 97/220 [00:13<00:16,  7.69it/s] 45%|####4     | 98/220 [00:13<00:15,  7.78it/s] 45%|####5     | 99/220 [00:13<00:14,  8.14it/s] 45%|####5     | 100/220 [00:13<00:14,  8.10it/s] 46%|####5     | 101/220 [00:13<00:14,  8.06it/s] 46%|####6     | 102/220 [00:14<00:14,  8.04it/s] 47%|####6     | 103/220 [00:14<00:14,  8.34it/s] 47%|####7     | 104/220 [00:14<00:14,  8.24it/s] 48%|####7     | 105/220 [00:14<00:14,  8.16it/s] 48%|####8     | 106/220 [00:14<00:13,  8.43it/s] 49%|####8     | 107/220 [00:14<00:13,  8.30it/s] 49%|####9     | 108/220 [00:14<00:13,  8.53it/s] 50%|####9     | 109/220 [00:14<00:13,  8.37it/s] 50%|#####     | 110/220 [00:15<00:12,  8.58it/s] 50%|#####     | 111/220 [00:15<00:12,  8.40it/s] 51%|#####     | 112/220 [00:15<00:13,  8.27it/s] 51%|#####1    | 113/220 [00:15<00:13,  8.19it/s] 52%|#####1    | 114/220 [00:15<00:13,  8.13it/s] 52%|#####2    | 115/220 [00:15<00:12,  8.41it/s] 53%|#####2    | 116/220 [00:15<00:12,  8.28it/s] 53%|#####3    | 117/220 [00:15<00:12,  8.52it/s] 54%|#####3    | 118/220 [00:15<00:12,  8.36it/s] 54%|#####4    | 119/220 [00:16<00:12,  8.25it/s] 55%|#####4    | 120/220 [00:16<00:11,  8.50it/s] 55%|#####5    | 121/220 [00:16<00:11,  8.34it/s] 55%|#####5    | 122/220 [00:16<00:11,  8.24it/s] 56%|#####5    | 123/220 [00:16<00:11,  8.17it/s] 56%|#####6    | 124/220 [00:16<00:11,  8.43it/s] 57%|#####6    | 125/220 [00:16<00:11,  8.63it/s] 57%|#####7    | 126/220 [00:16<00:11,  8.43it/s] 58%|#####7    | 127/220 [00:17<00:11,  8.30it/s] 58%|#####8    | 128/220 [00:17<00:11,  8.21it/s] 59%|#####8    | 129/220 [00:17<00:10,  8.47it/s] 59%|#####9    | 130/220 [00:17<00:11,  8.01it/s] 60%|#####9    | 131/220 [00:17<00:10,  8.32it/s]                                                 {'loss': 0.4442, 'learning_rate': 4e-07, 'epoch': 3.0}
 60%|######    | 132/220 [00:17<00:10,  8.32it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, label_class, id, text. If __index_level_0__, label_class, id, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 150
  Batch size = 8

  0%|          | 0/19 [00:00<?, ?it/s][A
 21%|##1       | 4/19 [00:00<00:00, 36.56it/s][A
 42%|####2     | 8/19 [00:00<00:00, 29.21it/s][A
 63%|######3   | 12/19 [00:00<00:00, 28.25it/s][A
 79%|#######8  | 15/19 [00:00<00:00, 28.51it/s][A
 95%|#########4| 18/19 [00:00<00:00, 28.16it/s][A{'eval_loss': 0.47158071398735046, 'eval_precision': 0.8533333333333334, 'eval_recall': 1.0, 'eval_accuracy': 0.8533333333333334, 'eval_f1': 0.9208633093525179, 'eval_runtime': 0.7038, 'eval_samples_per_second': 213.121, 'eval_steps_per_second': 26.995, 'epoch': 3.0}                                                 

                                               [A 60%|######    | 132/220 [00:18<00:10,  8.32it/s]
100%|##########| 19/19 [00:00<00:00, 28.16it/s][A
                                               [A 60%|######    | 133/220 [00:18<00:24,  3.60it/s] 61%|######    | 134/220 [00:18<00:20,  4.17it/s] 61%|######1   | 135/220 [00:18<00:17,  4.77it/s] 62%|######1   | 136/220 [00:18<00:15,  5.48it/s] 62%|######2   | 137/220 [00:18<00:13,  6.17it/s] 63%|######2   | 138/220 [00:19<00:12,  6.60it/s] 63%|######3   | 139/220 [00:19<00:11,  7.18it/s] 64%|######3   | 140/220 [00:19<00:10,  7.40it/s] 64%|######4   | 141/220 [00:19<00:10,  7.57it/s] 65%|######4   | 142/220 [00:19<00:09,  7.97it/s] 65%|######5   | 143/220 [00:19<00:09,  8.29it/s] 65%|######5   | 144/220 [00:19<00:09,  7.90it/s] 66%|######5   | 145/220 [00:19<00:09,  8.23it/s] 66%|######6   | 146/220 [00:20<00:09,  8.16it/s] 67%|######6   | 147/220 [00:20<00:09,  7.53it/s] 67%|######7   | 148/220 [00:20<00:09,  7.67it/s] 68%|######7   | 149/220 [00:20<00:08,  8.06it/s] 68%|######8   | 150/220 [00:20<00:08,  8.04it/s] 69%|######8   | 151/220 [00:20<00:08,  8.34it/s] 69%|######9   | 152/220 [00:20<00:08,  8.24it/s] 70%|######9   | 153/220 [00:20<00:08,  8.15it/s] 70%|#######   | 154/220 [00:21<00:08,  8.11it/s] 70%|#######   | 155/220 [00:21<00:07,  8.39it/s] 71%|#######   | 156/220 [00:21<00:07,  8.61it/s] 71%|#######1  | 157/220 [00:21<00:07,  8.41it/s] 72%|#######1  | 158/220 [00:21<00:07,  8.29it/s] 72%|#######2  | 159/220 [00:21<00:07,  8.53it/s] 73%|#######2  | 160/220 [00:21<00:07,  8.36it/s] 73%|#######3  | 161/220 [00:21<00:07,  8.25it/s] 74%|#######3  | 162/220 [00:21<00:07,  8.17it/s] 74%|#######4  | 163/220 [00:22<00:06,  8.44it/s] 75%|#######4  | 164/220 [00:22<00:06,  8.52it/s] 75%|#######5  | 165/220 [00:22<00:06,  8.47it/s] 75%|#######5  | 166/220 [00:22<00:06,  8.66it/s] 76%|#######5  | 167/220 [00:22<00:06,  8.80it/s] 76%|#######6  | 168/220 [00:22<00:06,  8.54it/s] 77%|#######6  | 169/220 [00:22<00:05,  8.72it/s] 77%|#######7  | 170/220 [00:22<00:05,  8.84it/s] 78%|#######7  | 171/220 [00:23<00:05,  8.57it/s] 78%|#######8  | 172/220 [00:23<00:05,  8.73it/s] 79%|#######8  | 173/220 [00:23<00:05,  8.50it/s] 79%|#######9  | 174/220 [00:23<00:05,  8.68it/s] 80%|#######9  | 175/220 [00:23<00:05,  8.81it/s]                                                 {'loss': 0.4212, 'learning_rate': 2e-07, 'epoch': 4.0}
 80%|########  | 176/220 [00:23<00:04,  8.81it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, label_class, id, text. If __index_level_0__, label_class, id, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 150
  Batch size = 8

  0%|          | 0/19 [00:00<?, ?it/s][A
 21%|##1       | 4/19 [00:00<00:00, 36.57it/s][A
 42%|####2     | 8/19 [00:00<00:00, 31.31it/s][A
 63%|######3   | 12/19 [00:00<00:00, 28.42it/s][A
 79%|#######8  | 15/19 [00:00<00:00, 28.09it/s][A
 95%|#########4| 18/19 [00:00<00:00, 27.87it/s][A                                                 {'eval_loss': 0.458461195230484, 'eval_precision': 0.8533333333333334, 'eval_recall': 1.0, 'eval_accuracy': 0.8533333333333334, 'eval_f1': 0.9208633093525179, 'eval_runtime': 0.7031, 'eval_samples_per_second': 213.335, 'eval_steps_per_second': 27.022, 'epoch': 4.0}
                                               [A
 80%|########  | 176/220 [00:24<00:04,  8.81it/s]
100%|##########| 19/19 [00:00<00:00, 27.87it/s][A
                                               [A 80%|########  | 177/220 [00:24<00:11,  3.65it/s] 81%|########  | 178/220 [00:24<00:09,  4.29it/s] 81%|########1 | 179/220 [00:24<00:08,  4.98it/s] 82%|########1 | 180/220 [00:24<00:07,  5.55it/s] 82%|########2 | 181/220 [00:24<00:06,  6.24it/s] 83%|########2 | 182/220 [00:24<00:05,  6.86it/s] 83%|########3 | 183/220 [00:25<00:05,  7.15it/s] 84%|########3 | 184/220 [00:25<00:04,  7.64it/s] 84%|########4 | 185/220 [00:25<00:04,  8.03it/s] 85%|########4 | 186/220 [00:25<00:04,  8.02it/s] 85%|########5 | 187/220 [00:25<00:03,  8.32it/s] 85%|########5 | 188/220 [00:25<00:03,  8.55it/s] 86%|########5 | 189/220 [00:25<00:03,  8.72it/s] 86%|########6 | 190/220 [00:25<00:03,  8.49it/s] 87%|########6 | 191/220 [00:25<00:03,  8.68it/s] 87%|########7 | 192/220 [00:26<00:03,  8.81it/s] 88%|########7 | 193/220 [00:26<00:03,  8.55it/s] 88%|########8 | 194/220 [00:26<00:02,  8.71it/s] 89%|########8 | 195/220 [00:26<00:02,  8.84it/s] 89%|########9 | 196/220 [00:26<00:02,  8.57it/s] 90%|########9 | 197/220 [00:26<00:02,  8.73it/s] 90%|######### | 198/220 [00:26<00:02,  8.85it/s] 90%|######### | 199/220 [00:26<00:02,  8.58it/s] 91%|######### | 200/220 [00:27<00:02,  8.74it/s] 91%|#########1| 201/220 [00:27<00:02,  8.86it/s] 92%|#########1| 202/220 [00:27<00:02,  8.58it/s] 92%|#########2| 203/220 [00:27<00:01,  8.74it/s] 93%|#########2| 204/220 [00:27<00:01,  8.51it/s] 93%|#########3| 205/220 [00:27<00:01,  8.69it/s] 94%|#########3| 206/220 [00:27<00:01,  8.82it/s] 94%|#########4| 207/220 [00:27<00:01,  8.55it/s] 95%|#########4| 208/220 [00:27<00:01,  8.72it/s] 95%|#########5| 209/220 [00:28<00:01,  8.84it/s] 95%|#########5| 210/220 [00:28<00:01,  8.57it/s] 96%|#########5| 211/220 [00:28<00:01,  8.74it/s] 96%|#########6| 212/220 [00:28<00:00,  8.85it/s] 97%|#########6| 213/220 [00:28<00:00,  8.58it/s] 97%|#########7| 214/220 [00:28<00:00,  8.74it/s] 98%|#########7| 215/220 [00:28<00:00,  8.85it/s] 98%|#########8| 216/220 [00:28<00:00,  8.58it/s] 99%|#########8| 217/220 [00:28<00:00,  8.74it/s] 99%|#########9| 218/220 [00:29<00:00,  8.85it/s]100%|#########9| 219/220 [00:29<00:00,  8.58it/s]{'loss': 0.4073, 'learning_rate': 0.0, 'epoch': 5.0}
                                                 100%|##########| 220/220 [00:29<00:00,  8.58it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, label_class, id, text. If __index_level_0__, label_class, id, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 150
  Batch size = 8

  0%|          | 0/19 [00:00<?, ?it/s][A
 21%|##1       | 4/19 [00:00<00:00, 36.58it/s][A
 42%|####2     | 8/19 [00:00<00:00, 31.31it/s][A
 63%|######3   | 12/19 [00:00<00:00, 28.42it/s][A
 79%|#######8  | 15/19 [00:00<00:00, 28.09it/s][A
 95%|#########4| 18/19 [00:00<00:00, 27.87it/s][A                                                 
                                               [A{'eval_loss': 0.45492440462112427, 'eval_precision': 0.8533333333333334, 'eval_recall': 1.0, 'eval_accuracy': 0.8533333333333334, 'eval_f1': 0.9208633093525179, 'eval_runtime': 0.7152, 'eval_samples_per_second': 209.735, 'eval_steps_per_second': 26.566, 'epoch': 5.0}
100%|##########| 220/220 [00:30<00:00,  8.58it/s]
100%|##########| 19/19 [00:00<00:00, 27.87it/s][A
                                               [A

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 30.0518, 'train_samples_per_second': 58.233, 'train_steps_per_second': 7.321, 'train_loss': 0.47453677437522196, 'epoch': 5.0}
100%|##########| 220/220 [00:30<00:00,  8.58it/s]100%|##########| 220/220 [00:30<00:00,  7.33it/s]
The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, label_class, id, text. If __index_level_0__, label_class, id, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 150
  Batch size = 8
  0%|          | 0/19 [00:00<?, ?it/s] 21%|##1       | 4/19 [00:00<00:00, 36.58it/s] 42%|####2     | 8/19 [00:00<00:00, 31.31it/s] 63%|######3   | 12/19 [00:00<00:00, 28.37it/s] 79%|#######8  | 15/19 [00:00<00:00, 28.05it/s] 95%|#########4| 18/19 [00:00<00:00, 27.85it/s]100%|##########| 19/19 [00:00<00:00, 28.26it/s]
INFO: [root] ***** Final Eval *****
 {'eval_loss': 0.45492440462112427, 'eval_precision': 0.8533333333333334, 'eval_recall': 1.0, 'eval_accuracy': 0.8533333333333334, 'eval_f1': 0.9208633093525179, 'eval_runtime': 0.6881, 'eval_samples_per_second': 218.004, 'eval_steps_per_second': 27.614, 'epoch': 5.0}
Saving model checkpoint to C:/Users/Admin/Desktop/dev/kk/azb_klassifizierer/experiment_saves/current_model
Configuration saved in C:/Users/Admin/Desktop/dev/kk/azb_klassifizierer/experiment_saves/current_model\config.json
Model weights saved in C:/Users/Admin/Desktop/dev/kk/azb_klassifizierer/experiment_saves/current_model\pytorch_model.bin
tokenizer config file saved in C:/Users/Admin/Desktop/dev/kk/azb_klassifizierer/experiment_saves/current_model\tokenizer_config.json
Special tokens file saved in C:/Users/Admin/Desktop/dev/kk/azb_klassifizierer/experiment_saves/current_model\special_tokens_map.json
